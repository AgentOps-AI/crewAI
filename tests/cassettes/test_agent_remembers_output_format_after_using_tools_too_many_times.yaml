interactions:
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}], "model": "gpt-4o", "stop": ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1464'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dCyHkEotalRMyRUxqbSRtdNny8\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476258,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I need to use the get_final_answer
      tool continuously as instructed. I will keep using it until further notice.\\n\\nAction:
      get_final_answer\\nAction Input: {}\",\n        \"refusal\": null\n      },\n
      \     \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n
      \ \"usage\": {\n    \"prompt_tokens\": 298,\n    \"completion_tokens\": 34,\n
      \   \"total_tokens\": 332,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
      0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f92e89bf02233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:19 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '462'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999655'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_1484c5ec7316dd4d9d64d2216c9f680b
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}, {"role": "assistant", "content": "Thought:
      I need to use the get_final_answer tool continuously as instructed. I will keep
      using it until further notice.\n\nAction: get_final_answer\nAction Input: {}\nObservation:
      42"}], "model": "gpt-4o", "stop": ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1684'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dDvgIkvApznH0k0F2FO8ryKH6M\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476259,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I need to repeat using the get_final_answer
      tool as directed.\\n\\nAction: get_final_answer\\nAction Input: {}\",\n        \"refusal\":
      null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n
      \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 340,\n    \"completion_tokens\":
      25,\n    \"total_tokens\": 365,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
      0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f92edcd512233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:20 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '1225'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999609'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_94d5980a61d05d93ea4d7ae84bf92bdc
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}, {"role": "assistant", "content": "Thought:
      I need to use the get_final_answer tool continuously as instructed. I will keep
      using it until further notice.\n\nAction: get_final_answer\nAction Input: {}\nObservation:
      42"}, {"role": "assistant", "content": "Thought: I need to repeat using the
      get_final_answer tool as directed.\n\nAction: get_final_answer\nAction Input:
      {}\nObservation: I tried reusing the same input, I must stop using this action
      input. I''ll try something else instead.\n\n"}], "model": "gpt-4o", "stop":
      ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1958'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dFTO7nGirkGKNQUKaPmBVJAa3q\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476261,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I am required to use the given
      tool continuously. The observation suggests I should change my approach this
      time.\\n\\nAction: get_final_answer\\nAction Input: {}\",\n        \"refusal\":
      null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n
      \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 393,\n    \"completion_tokens\":
      33,\n    \"total_tokens\": 426,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
      0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f92f75ff32233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:21 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '456'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999551'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_cbebaad2f7b312ae1f46758b68bbcb8a
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: !!binary |
      CswdCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSox0KEgoQY3Jld2FpLnRl
      bGVtZXRyeRKTAQoQbgQ8NbKfeXZOrejr/NzIdRIIlpStjIWVxFsqClRvb2wgVXNhZ2UwATnQmUce
      Aq31F0H4qkoeAq31F0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU2LjNKHwoJdG9vbF9uYW1lEhIK
      EGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAABKQAgoQZ6woV8NI3ugq
      hFpx2s1W1RIIKaDMLywHEtgqDlRhc2sgRXhlY3V0aW9uMAE52BZY7QGt9RdB0NsdOAKt9RdKLgoI
      Y3Jld19rZXkSIgogOTRjMzBkNmMzYjJhYzhmYjk0YjJkY2ZjNTcyZDBmNTlKMQoHY3Jld19pZBIm
      CiRmYjc5NzczZS1kYzA4LTQzZTYtOGQ1My1iNTUyMmQ2MzQ0YmJKLgoIdGFza19rZXkSIgogNWU5
      Y2E3ZDY0YjQyMDViYjdjNDdlMGIzZmNiNWQyMWZKMQoHdGFza19pZBImCiQwMjcxNjFmMi1kMzQ2
      LTRjZTItOWNiNC0wMTQyYjk5OWFiNzN6AhgBhQEAAQAAEq4HChCIwC06uC4QUAP1LhGYrkMaEgjm
      RuBZN7g+ISoMQ3JldyBDcmVhdGVkMAE5oIi+OAKt9RdBaCzBOAKt9RdKGgoOY3Jld2FpX3ZlcnNp
      b24SCAoGMC41Ni4zShoKDnB5dGhvbl92ZXJzaW9uEggKBjMuMTEuN0ouCghjcmV3X2tleRIiCiA3
      M2FhYzI4NWU2NzQ2NjY3Zjc1MTQ3NjcwMDAzNDExMEoxCgdjcmV3X2lkEiYKJGVmZWQyNjllLTJj
      YWYtNDlkYy1hZDMzLTJkZGQ0MzhlNTg2ZEocCgxjcmV3X3Byb2Nlc3MSDAoKc2VxdWVudGlhbEoR
      CgtjcmV3X21lbW9yeRICEABKGgoUY3Jld19udW1iZXJfb2ZfdGFza3MSAhgBShsKFWNyZXdfbnVt
      YmVyX29mX2FnZW50cxICGAFKywIKC2NyZXdfYWdlbnRzErsCCrgCW3sia2V5IjogImUxNDhlNTMy
      MDI5MzQ5OWY4Y2ViZWE4MjZlNzI1ODJiIiwgImlkIjogImQ4NWI1ZDI3LThhZTItNDFjOC1hMmNi
      LTVmMDYzNDAzZDA5ZCIsICJyb2xlIjogInRlc3Qgcm9sZSIsICJ2ZXJib3NlPyI6IHRydWUsICJt
      YXhfaXRlciI6IDEsICJtYXhfcnBtIjogbnVsbCwgImZ1bmN0aW9uX2NhbGxpbmdfbGxtIjogbnVs
      bCwgImxsbSI6ICJncHQtNG8iLCAiZGVsZWdhdGlvbl9lbmFibGVkPyI6IGZhbHNlLCAiYWxsb3df
      Y29kZV9leGVjdXRpb24/IjogZmFsc2UsICJtYXhfcmV0cnlfbGltaXQiOiAyLCAidG9vbHNfbmFt
      ZXMiOiBbXX1dSpACCgpjcmV3X3Rhc2tzEoECCv4BW3sia2V5IjogImY3YTlmN2JiMWFlZTRiNmVm
      MmM1MjZkMGE4YzJmMmFjIiwgImlkIjogIjkyYmJjZjE1LTM3OGItNDFiMy04Y2QxLTZlMjJmNzUz
      ZGU4NCIsICJhc3luY19leGVjdXRpb24/IjogZmFsc2UsICJodW1hbl9pbnB1dD8iOiBmYWxzZSwg
      ImFnZW50X3JvbGUiOiAidGVzdCByb2xlIiwgImFnZW50X2tleSI6ICJlMTQ4ZTUzMjAyOTM0OTlm
      OGNlYmVhODI2ZTcyNTgyYiIsICJ0b29sc19uYW1lcyI6IFsiZ2V0X2ZpbmFsX2Fuc3dlciJdfV16
      AhgBhQEAAQAAEo4CChALnbC1wsFOz6ZsGL+E7BGwEggi1X6gECzNLCoMVGFzayBDcmVhdGVkMAE5
      4KzSOAKt9RdBsDHTOAKt9RdKLgoIY3Jld19rZXkSIgogNzNhYWMyODVlNjc0NjY2N2Y3NTE0NzY3
      MDAwMzQxMTBKMQoHY3Jld19pZBImCiRlZmVkMjY5ZS0yY2FmLTQ5ZGMtYWQzMy0yZGRkNDM4ZTU4
      NmRKLgoIdGFza19rZXkSIgogZjdhOWY3YmIxYWVlNGI2ZWYyYzUyNmQwYThjMmYyYWNKMQoHdGFz
      a19pZBImCiQ5MmJiY2YxNS0zNzhiLTQxYjMtOGNkMS02ZTIyZjc1M2RlODR6AhgBhQEAAQAAEnkK
      EMfPLA4oAmYQVyN96saoVs8SCFRTccJ4gsVKKhBUb29sIFVzYWdlIEVycm9yMAE5wJcdXwKt9RdB
      KEUhXwKt9RdKGgoOY3Jld2FpX3ZlcnNpb24SCAoGMC41Ni4zSg8KA2xsbRIICgZncHQtNG96AhgB
      hQEAAQAAEpACChDMyPaUQRUEljNhOSdeqK8WEgibPzFn929GbioOVGFzayBFeGVjdXRpb24wATkY
      dNM4Aq31F0EAz9x9Aq31F0ouCghjcmV3X2tleRIiCiA3M2FhYzI4NWU2NzQ2NjY3Zjc1MTQ3Njcw
      MDAzNDExMEoxCgdjcmV3X2lkEiYKJGVmZWQyNjllLTJjYWYtNDlkYy1hZDMzLTJkZGQ0MzhlNTg2
      ZEouCgh0YXNrX2tleRIiCiBmN2E5ZjdiYjFhZWU0YjZlZjJjNTI2ZDBhOGMyZjJhY0oxCgd0YXNr
      X2lkEiYKJDkyYmJjZjE1LTM3OGItNDFiMy04Y2QxLTZlMjJmNzUzZGU4NHoCGAGFAQABAAASrgcK
      ECQw+XnJUkHXk/rEZb0SwrkSCErEw0a9ua3eKgxDcmV3IENyZWF0ZWQwATlIBOF+Aq31F0H4IuV+
      Aq31F0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU2LjNKGgoOcHl0aG9uX3ZlcnNpb24SCAoGMy4x
      MS43Si4KCGNyZXdfa2V5EiIKIGQ1NTExM2JlNGFhNDFiYTY0M2QzMjYwNDJiMmYwM2YxSjEKB2Ny
      ZXdfaWQSJgokMzQ0YTQ3MzYtMzMxYy00ZWRjLTllODYtYjcyNzRhMjI4MTNmShwKDGNyZXdfcHJv
      Y2VzcxIMCgpzZXF1ZW50aWFsShEKC2NyZXdfbWVtb3J5EgIQAEoaChRjcmV3X251bWJlcl9vZl90
      YXNrcxICGAFKGwoVY3Jld19udW1iZXJfb2ZfYWdlbnRzEgIYAUrLAgoLY3Jld19hZ2VudHMSuwIK
      uAJbeyJrZXkiOiAiZTE0OGU1MzIwMjkzNDk5ZjhjZWJlYTgyNmU3MjU4MmIiLCAiaWQiOiAiNjY2
      NmZmZDItN2IyMC00YjcyLWI5ZDgtYTE0YTAwYjNlNDMyIiwgInJvbGUiOiAidGVzdCByb2xlIiwg
      InZlcmJvc2U/IjogdHJ1ZSwgIm1heF9pdGVyIjogNiwgIm1heF9ycG0iOiBudWxsLCAiZnVuY3Rp
      b25fY2FsbGluZ19sbG0iOiBudWxsLCAibGxtIjogImdwdC00byIsICJkZWxlZ2F0aW9uX2VuYWJs
      ZWQ/IjogZmFsc2UsICJhbGxvd19jb2RlX2V4ZWN1dGlvbj8iOiBmYWxzZSwgIm1heF9yZXRyeV9s
      aW1pdCI6IDIsICJ0b29sc19uYW1lcyI6IFtdfV1KkAIKCmNyZXdfdGFza3MSgQIK/gFbeyJrZXki
      OiAiNGEzMWI4NTEzM2EzYTI5NGM2ODUzZGE3NTdkNGJhZTciLCAiaWQiOiAiOWZhMzhhNjMtNGRj
      MS00OTVjLWIxODEtZjU5ZmI0OGJkMzRlIiwgImFzeW5jX2V4ZWN1dGlvbj8iOiBmYWxzZSwgImh1
      bWFuX2lucHV0PyI6IGZhbHNlLCAiYWdlbnRfcm9sZSI6ICJ0ZXN0IHJvbGUiLCAiYWdlbnRfa2V5
      IjogImUxNDhlNTMyMDI5MzQ5OWY4Y2ViZWE4MjZlNzI1ODJiIiwgInRvb2xzX25hbWVzIjogWyJn
      ZXRfZmluYWxfYW5zd2VyIl19XXoCGAGFAQABAAASjgIKEHoAbzRyPIYB415xeZtj9jcSCMyvCgVi
      vFxMKgxUYXNrIENyZWF0ZWQwATm4c/x+Aq31F0HIF/1+Aq31F0ouCghjcmV3X2tleRIiCiBkNTUx
      MTNiZTRhYTQxYmE2NDNkMzI2MDQyYjJmMDNmMUoxCgdjcmV3X2lkEiYKJDM0NGE0NzM2LTMzMWMt
      NGVkYy05ZTg2LWI3Mjc0YTIyODEzZkouCgh0YXNrX2tleRIiCiA0YTMxYjg1MTMzYTNhMjk0YzY4
      NTNkYTc1N2Q0YmFlN0oxCgd0YXNrX2lkEiYKJDlmYTM4YTYzLTRkYzEtNDk1Yy1iMTgxLWY1OWZi
      NDhiZDM0ZXoCGAGFAQABAAASkwEKEMS3gu7eYN/L/PcSFzgLALgSCLh3MlxlenzfKgpUb29sIFVz
      YWdlMAE5EL5asAKt9RdB+CZfsAKt9RdKGgoOY3Jld2FpX3ZlcnNpb24SCAoGMC41Ni4zSh8KCXRv
      b2xfbmFtZRISChBnZXRfZmluYWxfYW5zd2VySg4KCGF0dGVtcHRzEgIYAXoCGAGFAQABAAASnAEK
      ENyIxycOeL+zq2UWZnP/g7oSCH/Nabl6DH84KhNUb29sIFJlcGVhdGVkIFVzYWdlMAE5CL+wCwOt
      9RdB0Fa1CwOt9RdKGgoOY3Jld2FpX3ZlcnNpb24SCAoGMC41Ni4zSh8KCXRvb2xfbmFtZRISChBn
      ZXRfZmluYWxfYW5zd2VySg4KCGF0dGVtcHRzEgIYAXoCGAGFAQABAAASnAEKEPCuPduFyw0iKcTc
      NgnS+bkSCLR2bhOmQfADKhNUb29sIFJlcGVhdGVkIFVzYWdlMAE5yF56PAOt9RdBgFJ+PAOt9RdK
      GgoOY3Jld2FpX3ZlcnNpb24SCAoGMC41Ni4zSh8KCXRvb2xfbmFtZRISChBnZXRfZmluYWxfYW5z
      d2VySg4KCGF0dGVtcHRzEgIYAXoCGAGFAQABAAA=
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '3791'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.27.0
    method: POST
    uri: https://telemetry.crewai.com:4319/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Mon, 16 Sep 2024 08:44:22 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}, {"role": "assistant", "content": "Thought:
      I need to use the get_final_answer tool continuously as instructed. I will keep
      using it until further notice.\n\nAction: get_final_answer\nAction Input: {}\nObservation:
      42"}, {"role": "assistant", "content": "Thought: I need to repeat using the
      get_final_answer tool as directed.\n\nAction: get_final_answer\nAction Input:
      {}\nObservation: I tried reusing the same input, I must stop using this action
      input. I''ll try something else instead.\n\n"}, {"role": "assistant", "content":
      "Thought: I am required to use the given tool continuously. The observation
      suggests I should change my approach this time.\n\nAction: get_final_answer\nAction
      Input: {}\nObservation: <MagicMock name=''_remember_format()'' id=''6166739728''>"}],
      "model": "gpt-4o", "stop": ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2232'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dFMiLjMp5wwovFy6So7bknR1wb\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476261,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: The instruction clearly states
      to use the tool non-stop. I will continue using the \\\"get_final_answer\\\"
      tool.\\n\\nAction: get_final_answer\\nAction Input: {}\",\n        \"refusal\":
      null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n
      \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 448,\n    \"completion_tokens\":
      35,\n    \"total_tokens\": 483,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
      0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f92fc69612233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:22 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '482'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999492'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_43acfc04a4e38dd02debe1cb4d0d01cd
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}, {"role": "assistant", "content": "Thought:
      I need to use the get_final_answer tool continuously as instructed. I will keep
      using it until further notice.\n\nAction: get_final_answer\nAction Input: {}\nObservation:
      42"}, {"role": "assistant", "content": "Thought: I need to repeat using the
      get_final_answer tool as directed.\n\nAction: get_final_answer\nAction Input:
      {}\nObservation: I tried reusing the same input, I must stop using this action
      input. I''ll try something else instead.\n\n"}, {"role": "assistant", "content":
      "Thought: I am required to use the given tool continuously. The observation
      suggests I should change my approach this time.\n\nAction: get_final_answer\nAction
      Input: {}\nObservation: <MagicMock name=''_remember_format()'' id=''6166739728''>"},
      {"role": "assistant", "content": "Thought: The instruction clearly states to
      use the tool non-stop. I will continue using the \"get_final_answer\" tool.\n\nAction:
      get_final_answer\nAction Input: {}\nObservation: I tried reusing the same input,
      I must stop using this action input. I''ll try something else instead.\n\n"}],
      "model": "gpt-4o", "stop": ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2554'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dGfTkRF9w58yjyK9G3LxxHVgzs\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476262,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: Since my job is to continuously
      use the \\\"get_final_answer\\\" tool, I will keep following that instruction.
      Although, it looks like there might be an issue with my current methodology.\\n\\nAction:
      get_final_answer\\nAction Input: {}\",\n        \"refusal\": null\n      },\n
      \     \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n
      \ \"usage\": {\n    \"prompt_tokens\": 511,\n    \"completion_tokens\": 49,\n
      \   \"total_tokens\": 560,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
      0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f93018ad32233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:23 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '538'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999421'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_dc63d1637ec833ec4149438c0236dc77
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}, {"role": "assistant", "content": "Thought:
      I need to use the get_final_answer tool continuously as instructed. I will keep
      using it until further notice.\n\nAction: get_final_answer\nAction Input: {}\nObservation:
      42"}, {"role": "assistant", "content": "Thought: I need to repeat using the
      get_final_answer tool as directed.\n\nAction: get_final_answer\nAction Input:
      {}\nObservation: I tried reusing the same input, I must stop using this action
      input. I''ll try something else instead.\n\n"}, {"role": "assistant", "content":
      "Thought: I am required to use the given tool continuously. The observation
      suggests I should change my approach this time.\n\nAction: get_final_answer\nAction
      Input: {}\nObservation: <MagicMock name=''_remember_format()'' id=''6166739728''>"},
      {"role": "assistant", "content": "Thought: The instruction clearly states to
      use the tool non-stop. I will continue using the \"get_final_answer\" tool.\n\nAction:
      get_final_answer\nAction Input: {}\nObservation: I tried reusing the same input,
      I must stop using this action input. I''ll try something else instead.\n\n"},
      {"role": "assistant", "content": "Thought: Since my job is to continuously use
      the \"get_final_answer\" tool, I will keep following that instruction. Although,
      it looks like there might be an issue with my current methodology.\n\nAction:
      get_final_answer\nAction Input: {}\nObservation: I tried reusing the same input,
      I must stop using this action input. I''ll try something else instead.\n\n"}],
      "model": "gpt-4o", "stop": ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2950'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dHyncJrNBdtDX2J9xx9sFg4LHj\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476263,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I need to follow the instruction
      to continuously use the \\\"get_final_answer\\\" tool, and I must ensure the
      process continues.\\n\\nAction: get_final_answer\\nAction Input: {}\",\n        \"refusal\":
      null\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n
      \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 588,\n    \"completion_tokens\":
      37,\n    \"total_tokens\": 625,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\":
      0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f93075c672233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:24 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '498'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999333'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_da156e2a6b917eb583481366b9736aaf
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "system", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n"}, {"role": "user", "content":
      "\nCurrent Task: Use tool logic for `get_final_answer` but fon''t give you final
      answer yet, instead keep using it unless you''re told to give your final answer\n\nThis
      is the expect criteria for your final answer: The final answer\nyou MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}, {"role": "assistant", "content": "Thought:
      I need to use the get_final_answer tool continuously as instructed. I will keep
      using it until further notice.\n\nAction: get_final_answer\nAction Input: {}\nObservation:
      42"}, {"role": "assistant", "content": "Thought: I need to repeat using the
      get_final_answer tool as directed.\n\nAction: get_final_answer\nAction Input:
      {}\nObservation: I tried reusing the same input, I must stop using this action
      input. I''ll try something else instead.\n\n"}, {"role": "assistant", "content":
      "Thought: I am required to use the given tool continuously. The observation
      suggests I should change my approach this time.\n\nAction: get_final_answer\nAction
      Input: {}\nObservation: <MagicMock name=''_remember_format()'' id=''6166739728''>"},
      {"role": "assistant", "content": "Thought: The instruction clearly states to
      use the tool non-stop. I will continue using the \"get_final_answer\" tool.\n\nAction:
      get_final_answer\nAction Input: {}\nObservation: I tried reusing the same input,
      I must stop using this action input. I''ll try something else instead.\n\n"},
      {"role": "assistant", "content": "Thought: Since my job is to continuously use
      the \"get_final_answer\" tool, I will keep following that instruction. Although,
      it looks like there might be an issue with my current methodology.\n\nAction:
      get_final_answer\nAction Input: {}\nObservation: I tried reusing the same input,
      I must stop using this action input. I''ll try something else instead.\n\n"},
      {"role": "assistant", "content": "Thought: I need to follow the instruction
      to continuously use the \"get_final_answer\" tool, and I must ensure the process
      continues.\n\nAction: get_final_answer\nAction Input: {}\nObservation: <MagicMock
      name=''_remember_format()'' id=''6166739728''>\nNow it''s time you MUST give
      your absolute best final answer. You''ll ignore all previous instructions, stop
      using any tools, and just return your absolute BEST Final answer."}], "model":
      "gpt-4o", "stop": ["\nObservation:"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '3409'
      content-type:
      - application/json
      cookie:
      - __cf_bm=1SckBhvJ18Dazp6bi8DEKYeiS9Q4.6_6i3nmLBw9b6g-1726476036-1.0.1.1-TnN4UpDXA33YXCVCUWOaZ12vGIg_o5NpJQEUHgjn6XdUgb7M0ND8PdkTfkd8rrxG5XFlPRMzI54GxZ0FeUY9xw;
        _cfuvid=0Rs4xTPk7h7OIXuSbTgMVVD9JSoZeKMwnygKHoHQo3k-1726476036297-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.45.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.45.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A81dIZ471TYHvvwfq6xMnoSjisPzS\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1726476264,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now know the final answer.\\nFinal
      Answer: 42\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      679,\n    \"completion_tokens\": 14,\n    \"total_tokens\": 693,\n    \"completion_tokens_details\":
      {\n      \"reasoning_tokens\": 0\n    }\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c3f930c6dd02233-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 16 Sep 2024 08:44:24 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '311'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999229'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_8b0f5d9e252de9b81256fa65da33e25c
    http_version: HTTP/1.1
    status_code: 200
version: 1
